{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>2. Supervised Modelling</h1>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <b>ALEXANDER SCHINDLER</b>\n",
    "  <p style=\"font-size:9pt; text-align: center;color: gray;\">  \n",
    "Scientist<br>\n",
    "Information Management<br>\n",
    "Center for Digital Safety & Security<br>\n",
    "<br>\n",
    "      <b>AIT Austrian Institute of Technology GmbH</b><br>\n",
    "Giefinggasse 4 | 1210 Vienna | Austria<br>\n",
    "T +43 50550-2902 | M +43 664 8251454 | F +43 50550-2813<br>\n",
    "alexander.schindler@ait.ac.at | www.ait.ac.at<br>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:19:59.952633Z",
     "start_time": "2019-06-03T09:19:59.947477Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:00.789667Z",
     "start_time": "2019-06-03T09:19:59.955975Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import progressbar\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:00.795783Z",
     "start_time": "2019-06-03T09:20:00.792530Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH            = \"/datastorage_fast/FIDS30_all\"\n",
    "IMAGES_PATH          = \"/datastorage_fast/FIDS30_all\"\n",
    "IMAGES_LABELLED_PATH = \"/datastorage_fast/FIDS30\"\n",
    "\n",
    "store_dir            = \"/datastorage_fast/FIDS30_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:00.826304Z",
     "start_time": "2019-06-03T09:20:00.798328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/guava_32.jpg</td>\n",
       "      <td>guava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos\n",
       "3        /datastorage_fast/FIDS30_all/guava_32.jpg         guava\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "labels    = []\n",
    "\n",
    "for path, subdirs, files in os.walk(IMAGES_PATH):\n",
    "    for name in files:\n",
    "        if name.find(\".jpg\") != -1:\n",
    "            filenames.append(os.path.join(path, name))\n",
    "            labels.append(name.split(\"_\")[0])\n",
    "        \n",
    "metadata_images          = pd.DataFrame(filenames, columns=[\"Filename\"])\n",
    "metadata_images[\"label\"] = labels\n",
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:00.841478Z",
     "start_time": "2019-06-03T09:20:00.828224Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(img, height, width):\n",
    "    \n",
    "    is_color              = len(img.shape) == 3\n",
    "    src_height, src_width = img.shape[:2]\n",
    "    \n",
    "    # calc ratio\n",
    "    ratio = np.min([float(height) / src_height, float(width) / src_width])\n",
    "    \n",
    "    new_height = np.round(src_height * ratio).astype(int)\n",
    "    new_width  = np.round(src_width  * ratio).astype(int)\n",
    "    \n",
    "    img_reshaped = cv2.resize(img, (new_width,new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    if new_height < height:\n",
    "        \n",
    "        if is_color:\n",
    "            dims = (height - new_height, new_width, 3)\n",
    "        else:\n",
    "            dims = (height - new_height, new_width)\n",
    "        \n",
    "        padding      = np.ones(dims, dtype=np.uint8)\n",
    "        padding     *= 255\n",
    "        img_reshaped = np.concatenate([img_reshaped, padding], axis=0)\n",
    "    \n",
    "    elif new_width < width:\n",
    "        \n",
    "        if is_color:\n",
    "            dims = (new_height, width - new_width, 3)\n",
    "        else:\n",
    "            dims = (new_height, width - new_width)\n",
    "        \n",
    "        padding      = np.ones(dims, dtype=np.uint8)\n",
    "        padding     *= 255\n",
    "\n",
    "        img_reshaped = np.concatenate([img_reshaped, padding], axis=1)\n",
    "        \n",
    "    if not ((img_reshaped.shape[0] == height) & (img_reshaped.shape[1] == width)):\n",
    "        print(img_reshaped.shape)\n",
    "        raise Exception(\"resize error\")\n",
    "    \n",
    "    return img_reshaped, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:52.642740Z",
     "start_time": "2019-06-03T09:20:00.844153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (971 of 971) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n"
     ]
    }
   ],
   "source": [
    "pbar = progressbar.ProgressBar(max_value=metadata_images.shape[0])\n",
    "\n",
    "document_images     = []\n",
    "image_metadata_idx  = []\n",
    "failed_idx          = []\n",
    "\n",
    "for i, f_name in pbar(enumerate(metadata_images.Filename.values)):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        img = cv2.imread(f_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img, _ = resize_image(img, height=128, width=128)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.        \n",
    "        \n",
    "        document_images.append(img)\n",
    "        image_metadata_idx.append(i)\n",
    "        \n",
    "    except:\n",
    "        failed_idx.append(i)\n",
    "\n",
    "document_images = np.array(document_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:52.656642Z",
     "start_time": "2019-06-03T09:20:52.645611Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_images.loc[image_metadata_idx, \"image_nr\"] = np.arange(len(image_metadata_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:52.664991Z",
     "start_time": "2019-06-03T09:20:52.659940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_images = metadata_images[~metadata_images.image_nr.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:52.679456Z",
     "start_time": "2019-06-03T09:20:52.668008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "      <th>image_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/tomatoes_21.jpg</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label  image_nr\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons       0.0\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries       1.0\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos       2.0\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas       3.0\n",
       "5     /datastorage_fast/FIDS30_all/tomatoes_21.jpg      tomatoes       4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:54.205272Z",
     "start_time": "2019-06-03T09:20:52.681424Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.constraints import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:58.792664Z",
     "start_time": "2019-06-03T09:20:54.208699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 12)      336       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 12)        48        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 24)        2616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 48)        10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 96)        41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 1,636,498\n",
      "Trainable params: 1,636,132\n",
      "Non-trainable params: 366\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "inputs = Input((128, 128, 3))\n",
    "\n",
    "# normalize inputs\n",
    "inp = BatchNormalization()(inputs)\n",
    "\n",
    "# === cnn ===\n",
    "\n",
    "activation = 'relu'\n",
    "filtnr     = 12\n",
    "\n",
    "cnn = Conv2D(filtnr, 3, activation = activation, padding = 'same')(inp)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn) # 64x64\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*2, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn) # 32x32\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*4, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn) # 16x16\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*8, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn) # 8x8\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "# === Bottleneck ===\n",
    "cnn = Flatten()(cnn)\n",
    "\n",
    "fc  = Dense(256, activation=\"relu\")(cnn)\n",
    "out = Dense(30,  activation=\"softmax\")(fc)\n",
    "\n",
    "\n",
    "model         = Model(input = inputs, output = out)\n",
    "\n",
    "model.compile(optimizer = Adam(lr=0.0002), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ground-truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:58.815143Z",
     "start_time": "2019-06-03T09:20:58.796635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "      <th>image_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/tomatoes_21.jpg</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label  image_nr\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons       0.0\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries       1.0\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos       2.0\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas       3.0\n",
       "5     /datastorage_fast/FIDS30_all/tomatoes_21.jpg      tomatoes       4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.211828Z",
     "start_time": "2019-06-03T09:20:58.817735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerically encode string labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.222610Z",
     "start_time": "2019-06-03T09:20:59.215206Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lencoder = LabelEncoder()\n",
    "lencoder.fit(metadata_images.label)\n",
    "\n",
    "labels_encoded = lencoder.transform(metadata_images.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encode labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.228914Z",
     "start_time": "2019-06-03T09:20:59.225311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.246930Z",
     "start_time": "2019-06-03T09:20:59.231278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(labels_encoded.reshape(-1, 1))\n",
    "\n",
    "labels_ohe = ohe.transform(labels_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.255410Z",
     "start_time": "2019-06-03T09:20:59.249448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.278152Z",
     "start_time": "2019-06-03T09:20:59.257614Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.284278Z",
     "start_time": "2019-06-03T09:20:59.280568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss_tt = StratifiedShuffleSplit(n_splits=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.290334Z",
     "start_time": "2019-06-03T09:20:59.286912Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_splits = sss_tt.split(document_images, labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.306586Z",
     "start_time": "2019-06-03T09:20:59.292911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all_ids, test_ids = list(tt_splits)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.312626Z",
     "start_time": "2019-06-03T09:20:59.308960Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss_tv = StratifiedShuffleSplit(n_splits=1, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.530551Z",
     "start_time": "2019-06-03T09:20:59.317850Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv_splits = sss_tv.split(document_images[train_all_ids], labels_encoded[train_all_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.558034Z",
     "start_time": "2019-06-03T09:20:59.533460Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids_rel, val_ids_rel = list(tv_splits)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.564563Z",
     "start_time": "2019-06-03T09:20:59.560982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = train_all_ids[train_ids_rel]\n",
    "val_ids   = train_all_ids[val_ids_rel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.570172Z",
     "start_time": "2019-06-03T09:20:59.566885Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:20:59.576023Z",
     "start_time": "2019-06-03T09:20:59.572568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:00.814901Z",
     "start_time": "2019-06-03T09:20:59.578808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_nr += 1\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='/datastorage_fast/FIDS30_temp/%d' % model_nr, \n",
    "                                      histogram_freq=0, \n",
    "                                      batch_size=32, \n",
    "                                      write_graph=False, \n",
    "                                      write_grads=False, \n",
    "                                      write_images=False, \n",
    "                                      embeddings_freq=0, \n",
    "                                      embeddings_layer_names=None, \n",
    "                                      embeddings_metadata=None, \n",
    "                                      embeddings_data=None, \n",
    "                                      update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.291542Z",
     "start_time": "2019-06-03T09:21:00.818790Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 822 samples, validate on 44 samples\n",
      "Epoch 1/50\n",
      "822/822 [==============================] - 4s 5ms/step - loss: 3.3846 - acc: 0.1277 - val_loss: 2.9712 - val_acc: 0.1818\n",
      "Epoch 2/50\n",
      "822/822 [==============================] - 0s 529us/step - loss: 1.5070 - acc: 0.5998 - val_loss: 2.5703 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "822/822 [==============================] - 0s 573us/step - loss: 0.7228 - acc: 0.8589 - val_loss: 2.5479 - val_acc: 0.2727\n",
      "Epoch 4/50\n",
      "822/822 [==============================] - 0s 545us/step - loss: 0.3451 - acc: 0.9696 - val_loss: 2.4486 - val_acc: 0.3182\n",
      "Epoch 5/50\n",
      "822/822 [==============================] - 0s 504us/step - loss: 0.1560 - acc: 0.9951 - val_loss: 2.4323 - val_acc: 0.3409\n",
      "Epoch 6/50\n",
      "822/822 [==============================] - 0s 557us/step - loss: 0.0818 - acc: 1.0000 - val_loss: 2.4159 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "822/822 [==============================] - 0s 581us/step - loss: 0.0544 - acc: 1.0000 - val_loss: 2.4501 - val_acc: 0.2727\n",
      "Epoch 8/50\n",
      "822/822 [==============================] - 0s 482us/step - loss: 0.0443 - acc: 1.0000 - val_loss: 2.4781 - val_acc: 0.2727\n",
      "Epoch 9/50\n",
      "822/822 [==============================] - 0s 469us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 2.4673 - val_acc: 0.2727\n",
      "Epoch 10/50\n",
      "822/822 [==============================] - 0s 551us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 2.4202 - val_acc: 0.2955\n",
      "Epoch 11/50\n",
      "822/822 [==============================] - 0s 561us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 2.4428 - val_acc: 0.3182\n",
      "Epoch 12/50\n",
      "822/822 [==============================] - 0s 517us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.4533 - val_acc: 0.2955\n",
      "Epoch 13/50\n",
      "822/822 [==============================] - 0s 495us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.4559 - val_acc: 0.2727\n",
      "Epoch 14/50\n",
      "822/822 [==============================] - 0s 524us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.4489 - val_acc: 0.2727\n",
      "Epoch 15/50\n",
      "822/822 [==============================] - 0s 584us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 2.4683 - val_acc: 0.2955\n",
      "Epoch 16/50\n",
      "822/822 [==============================] - 0s 512us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.4913 - val_acc: 0.2955\n",
      "Epoch 17/50\n",
      "822/822 [==============================] - 0s 487us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.4969 - val_acc: 0.2955\n",
      "Epoch 18/50\n",
      "822/822 [==============================] - 0s 507us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.4880 - val_acc: 0.2955\n",
      "Epoch 19/50\n",
      "822/822 [==============================] - 0s 498us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.4858 - val_acc: 0.2955\n",
      "Epoch 20/50\n",
      "822/822 [==============================] - 0s 563us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.5036 - val_acc: 0.2955\n",
      "Epoch 21/50\n",
      "822/822 [==============================] - 0s 527us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.5218 - val_acc: 0.2955\n",
      "Epoch 22/50\n",
      "822/822 [==============================] - 0s 492us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.5161 - val_acc: 0.3182\n",
      "Epoch 23/50\n",
      "822/822 [==============================] - 0s 486us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.5197 - val_acc: 0.3182\n",
      "Epoch 24/50\n",
      "822/822 [==============================] - 0s 509us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.5245 - val_acc: 0.2955\n",
      "Epoch 25/50\n",
      "822/822 [==============================] - 0s 519us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.5282 - val_acc: 0.2955\n",
      "Epoch 26/50\n",
      "822/822 [==============================] - 0s 564us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5286 - val_acc: 0.3182\n",
      "Epoch 27/50\n",
      "822/822 [==============================] - 0s 497us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5289 - val_acc: 0.3182\n",
      "Epoch 28/50\n",
      "822/822 [==============================] - 0s 472us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.5338 - val_acc: 0.3182\n",
      "Epoch 29/50\n",
      "822/822 [==============================] - 0s 492us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5376 - val_acc: 0.3182\n",
      "Epoch 30/50\n",
      "822/822 [==============================] - 0s 509us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5390 - val_acc: 0.3182\n",
      "Epoch 31/50\n",
      "822/822 [==============================] - 0s 512us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.5471 - val_acc: 0.3182\n",
      "Epoch 32/50\n",
      "822/822 [==============================] - 0s 585us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5614 - val_acc: 0.3182\n",
      "Epoch 33/50\n",
      "822/822 [==============================] - 0s 475us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5452 - val_acc: 0.3182\n",
      "Epoch 34/50\n",
      "822/822 [==============================] - 0s 488us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.5464 - val_acc: 0.3182\n",
      "Epoch 35/50\n",
      "822/822 [==============================] - 0s 533us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.5525 - val_acc: 0.3182\n",
      "Epoch 36/50\n",
      "822/822 [==============================] - 0s 575us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.5449 - val_acc: 0.3182\n",
      "Epoch 37/50\n",
      "822/822 [==============================] - 0s 515us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.5431 - val_acc: 0.3182\n",
      "Epoch 38/50\n",
      "822/822 [==============================] - 0s 498us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.5498 - val_acc: 0.3182\n",
      "Epoch 39/50\n",
      "822/822 [==============================] - 0s 493us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.5516 - val_acc: 0.3182\n",
      "Epoch 40/50\n",
      "822/822 [==============================] - 0s 547us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.5599 - val_acc: 0.3182\n",
      "Epoch 41/50\n",
      "822/822 [==============================] - 0s 531us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.5666 - val_acc: 0.3409\n",
      "Epoch 42/50\n",
      "822/822 [==============================] - 0s 494us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.5697 - val_acc: 0.3409\n",
      "Epoch 43/50\n",
      "822/822 [==============================] - 0s 504us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.5728 - val_acc: 0.3182\n",
      "Epoch 44/50\n",
      "822/822 [==============================] - 0s 561us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.5763 - val_acc: 0.3182\n",
      "Epoch 45/50\n",
      "822/822 [==============================] - 0s 514us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.5836 - val_acc: 0.3182\n",
      "Epoch 46/50\n",
      "822/822 [==============================] - 0s 471us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.5859 - val_acc: 0.3409\n",
      "Epoch 47/50\n",
      "822/822 [==============================] - 0s 473us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.5958 - val_acc: 0.3409\n",
      "Epoch 48/50\n",
      "822/822 [==============================] - 0s 480us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.5905 - val_acc: 0.3409\n",
      "Epoch 49/50\n",
      "822/822 [==============================] - 0s 515us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5890 - val_acc: 0.3409\n",
      "Epoch 50/50\n",
      "822/822 [==============================] - 0s 519us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5878 - val_acc: 0.3182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa62c61e198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(document_images[train_ids], \n",
    "          labels_ohe[train_ids], \n",
    "          batch_size = 64,\n",
    "          epochs     = 50,\n",
    "          validation_data = (document_images[val_ids], labels_ohe[val_ids]),\n",
    "          callbacks=[tb_callback],\n",
    "          verbose    = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.299545Z",
     "start_time": "2019-06-03T09:21:28.294928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.310718Z",
     "start_time": "2019-06-03T09:21:28.302432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(featurewise_center=False, \n",
    "                                   samplewise_center=False, \n",
    "                                   featurewise_std_normalization=False, \n",
    "                                   samplewise_std_normalization=False, \n",
    "                                   zca_whitening=False, \n",
    "                                   zca_epsilon=1e-06, \n",
    "                                   rotation_range=90, \n",
    "                                   width_shift_range=10.0, \n",
    "                                   height_shift_range=10.0, \n",
    "                                   brightness_range=None, \n",
    "                                   shear_range=0.0, \n",
    "                                   zoom_range=10.0, \n",
    "                                   channel_shift_range=0.0, \n",
    "                                   fill_mode='constant', \n",
    "                                   cval=1.0, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True, \n",
    "                                   rescale=None, \n",
    "                                   preprocessing_function=None, \n",
    "                                   data_format=None, \n",
    "                                   validation_split=0.0, \n",
    "                                   dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.690848Z",
     "start_time": "2019-06-03T09:21:28.313017Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_train.fit(document_images[train_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.703186Z",
     "start_time": "2019-06-03T09:21:28.693906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_val = ImageDataGenerator(featurewise_center=False, \n",
    "                                 samplewise_center=False, \n",
    "                                 featurewise_std_normalization=False, \n",
    "                                 samplewise_std_normalization=False, \n",
    "                                 zca_whitening=False, \n",
    "                                 zca_epsilon=1e-06, \n",
    "                                 rotation_range=0, \n",
    "                                 width_shift_range=0.0, \n",
    "                                 height_shift_range=0.0, \n",
    "                                 brightness_range=None, \n",
    "                                 shear_range=0.0, \n",
    "                                 zoom_range=0.0, \n",
    "                                 channel_shift_range=0.0, \n",
    "                                 fill_mode='constant', \n",
    "                                 cval=1.0, \n",
    "                                 horizontal_flip=False, \n",
    "                                 vertical_flip=False, \n",
    "                                 rescale=None, \n",
    "                                 preprocessing_function=None, \n",
    "                                 data_format=None, \n",
    "                                 validation_split=0.0, \n",
    "                                 dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.720289Z",
     "start_time": "2019-06-03T09:21:28.706169Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_val.fit(document_images[val_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.726520Z",
     "start_time": "2019-06-03T09:21:28.723081Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_aug_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:21:28.735101Z",
     "start_time": "2019-06-03T09:21:28.729147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_aug_nr += 1\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='/datastorage_fast/FIDS30_temp/aug_%d' % model_aug_nr, \n",
    "                                      histogram_freq=0, \n",
    "                                      batch_size=32, \n",
    "                                      write_graph=False, \n",
    "                                      write_grads=False, \n",
    "                                      write_images=False, \n",
    "                                      embeddings_freq=0, \n",
    "                                      embeddings_layer_names=None, \n",
    "                                      embeddings_metadata=None, \n",
    "                                      embeddings_data=None, \n",
    "                                      update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:23:42.925655Z",
     "start_time": "2019-06-03T09:21:28.737480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/12 [==============================] - 3s 222ms/step - loss: 4.1325 - acc: 0.0730 - val_loss: 3.4724 - val_acc: 0.2273\n",
      "Epoch 2/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 3.2662 - acc: 0.1093 - val_loss: 3.8758 - val_acc: 0.2045\n",
      "Epoch 3/50\n",
      "13/12 [==============================] - 3s 223ms/step - loss: 3.0941 - acc: 0.1478 - val_loss: 3.7732 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "13/12 [==============================] - 3s 217ms/step - loss: 2.9019 - acc: 0.1616 - val_loss: 3.5949 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "13/12 [==============================] - 3s 210ms/step - loss: 2.8220 - acc: 0.1586 - val_loss: 3.3943 - val_acc: 0.2727\n",
      "Epoch 6/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 2.6661 - acc: 0.1879 - val_loss: 3.4003 - val_acc: 0.1818\n",
      "Epoch 7/50\n",
      "13/12 [==============================] - 3s 210ms/step - loss: 2.6294 - acc: 0.2054 - val_loss: 3.1814 - val_acc: 0.2045\n",
      "Epoch 8/50\n",
      "13/12 [==============================] - 3s 198ms/step - loss: 2.6127 - acc: 0.2172 - val_loss: 3.7825 - val_acc: 0.2500\n",
      "Epoch 9/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.6011 - acc: 0.2038 - val_loss: 3.6366 - val_acc: 0.2045\n",
      "Epoch 10/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 2.4067 - acc: 0.2511 - val_loss: 3.7054 - val_acc: 0.2273\n",
      "Epoch 11/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.4311 - acc: 0.2230 - val_loss: 4.0355 - val_acc: 0.1818\n",
      "Epoch 12/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.4089 - acc: 0.2605 - val_loss: 3.7751 - val_acc: 0.2045\n",
      "Epoch 13/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.3035 - acc: 0.2717 - val_loss: 3.3417 - val_acc: 0.2727\n",
      "Epoch 14/50\n",
      "13/12 [==============================] - 3s 212ms/step - loss: 2.2523 - acc: 0.2852 - val_loss: 3.1336 - val_acc: 0.2045\n",
      "Epoch 15/50\n",
      "13/12 [==============================] - 3s 206ms/step - loss: 2.2713 - acc: 0.2698 - val_loss: 3.4821 - val_acc: 0.1364\n",
      "Epoch 16/50\n",
      "13/12 [==============================] - 3s 206ms/step - loss: 2.2182 - acc: 0.2509 - val_loss: 3.7850 - val_acc: 0.2045\n",
      "Epoch 17/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 2.1976 - acc: 0.2836 - val_loss: 3.6357 - val_acc: 0.2273\n",
      "Epoch 18/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.1286 - acc: 0.3173 - val_loss: 3.2194 - val_acc: 0.2273\n",
      "Epoch 19/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 2.1431 - acc: 0.2997 - val_loss: 3.2321 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 2.1379 - acc: 0.3105 - val_loss: 3.1512 - val_acc: 0.1591\n",
      "Epoch 21/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.1722 - acc: 0.2904 - val_loss: 2.7927 - val_acc: 0.3182\n",
      "Epoch 22/50\n",
      "13/12 [==============================] - 3s 212ms/step - loss: 2.1205 - acc: 0.2896 - val_loss: 2.9799 - val_acc: 0.2273\n",
      "Epoch 23/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.1559 - acc: 0.2972 - val_loss: 2.7806 - val_acc: 0.2955\n",
      "Epoch 24/50\n",
      "13/12 [==============================] - 3s 217ms/step - loss: 2.1254 - acc: 0.2922 - val_loss: 2.9245 - val_acc: 0.2045\n",
      "Epoch 25/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 2.0660 - acc: 0.3131 - val_loss: 2.7496 - val_acc: 0.2955\n",
      "Epoch 26/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.0375 - acc: 0.3163 - val_loss: 3.1689 - val_acc: 0.2500\n",
      "Epoch 27/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 1.9716 - acc: 0.3289 - val_loss: 3.4478 - val_acc: 0.2955\n",
      "Epoch 28/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 1.9802 - acc: 0.3420 - val_loss: 2.9920 - val_acc: 0.2727\n",
      "Epoch 29/50\n",
      "13/12 [==============================] - 3s 212ms/step - loss: 1.9713 - acc: 0.3370 - val_loss: 2.7583 - val_acc: 0.2955\n",
      "Epoch 30/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 1.9507 - acc: 0.3618 - val_loss: 2.7172 - val_acc: 0.3182\n",
      "Epoch 31/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 1.9944 - acc: 0.3448 - val_loss: 2.6359 - val_acc: 0.3182\n",
      "Epoch 32/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 1.9783 - acc: 0.3578 - val_loss: 2.8636 - val_acc: 0.3182\n",
      "Epoch 33/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 2.0332 - acc: 0.3229 - val_loss: 2.7331 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 1.9367 - acc: 0.3614 - val_loss: 2.7183 - val_acc: 0.2500\n",
      "Epoch 35/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 1.9799 - acc: 0.3335 - val_loss: 2.6456 - val_acc: 0.3182\n",
      "Epoch 36/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 1.9532 - acc: 0.3530 - val_loss: 2.7769 - val_acc: 0.4318\n",
      "Epoch 37/50\n",
      "13/12 [==============================] - 3s 194ms/step - loss: 1.9632 - acc: 0.3366 - val_loss: 2.6122 - val_acc: 0.3409\n",
      "Epoch 38/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 1.8693 - acc: 0.3580 - val_loss: 2.7588 - val_acc: 0.3409\n",
      "Epoch 39/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 1.9021 - acc: 0.3731 - val_loss: 2.6706 - val_acc: 0.3182\n",
      "Epoch 40/50\n",
      "13/12 [==============================] - 3s 196ms/step - loss: 1.9168 - acc: 0.3528 - val_loss: 2.8291 - val_acc: 0.3182\n",
      "Epoch 41/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 1.9079 - acc: 0.3618 - val_loss: 2.7213 - val_acc: 0.3409\n",
      "Epoch 42/50\n",
      "13/12 [==============================] - 3s 210ms/step - loss: 1.8944 - acc: 0.3831 - val_loss: 2.6964 - val_acc: 0.3636\n",
      "Epoch 43/50\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 1.9259 - acc: 0.3413 - val_loss: 2.8767 - val_acc: 0.2500\n",
      "Epoch 44/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 1.8529 - acc: 0.3544 - val_loss: 3.1085 - val_acc: 0.3182\n",
      "Epoch 45/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 1.8474 - acc: 0.3674 - val_loss: 3.1570 - val_acc: 0.3409\n",
      "Epoch 46/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 1.8075 - acc: 0.3909 - val_loss: 2.9578 - val_acc: 0.3182\n",
      "Epoch 47/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 1.7483 - acc: 0.4194 - val_loss: 2.5360 - val_acc: 0.2955\n",
      "Epoch 48/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 1.8437 - acc: 0.3812 - val_loss: 2.6835 - val_acc: 0.3636\n",
      "Epoch 49/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 1.8293 - acc: 0.3855 - val_loss: 2.7160 - val_acc: 0.3182\n",
      "Epoch 50/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 1.8432 - acc: 0.4082 - val_loss: 2.8036 - val_acc: 0.2955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa218402e80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen_train.flow(document_images[train_ids], labels_ohe[train_ids], batch_size=64),\n",
    "                    validation_data = datagen_val.flow(document_images[val_ids], labels_ohe[val_ids], batch_size=12),\n",
    "                    steps_per_epoch = train_ids.shape[0] / 64, \n",
    "                    validation_steps= val_ids.shape[0] / 12,\n",
    "                    callbacks=[tb_callback],\n",
    "                    verbose=1,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:23:43.020604Z",
     "start_time": "2019-06-03T09:23:42.928917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 685us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.384141274334229, 0.29896907216494845]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(document_images[test_ids], labels_ohe[test_ids])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
