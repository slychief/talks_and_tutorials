{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<right><img src=\"iDSDL-Logo.png\" width=\"200px\" align=\"right\"></right>\n",
    "<br><br><br><br>\n",
    "\n",
    "<center>\n",
    "<h1>2. Supervised Modelling</h1>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "<b>Alexander Schindler (AIT/TU Wien)</b><br>\n",
    "schindler@ifs.tuwien.ac.at / alexander.schindler@ait.ac.at<br>\n",
    "<a href=\"http://www.ifs.tuwien.ac.at/%7Eschindler/\">http://www.ifs.tuwien.ac.at/~schindler/</a><br>\n",
    "<a href=\"https://www.linkedin.com/in/schindleralexander\">LinkedIn</a> | <a href=\"https://twitter.com/Slychief\">Twitter</a>\n",
    "        </center>\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:56:56.461102Z",
     "start_time": "2019-05-25T08:56:56.456136Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:56:57.285047Z",
     "start_time": "2019-05-25T08:56:56.463936Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import progressbar\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:56:57.291270Z",
     "start_time": "2019-05-25T08:56:57.287834Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH            = \"/datastorage_fast/FIDS30_all\"\n",
    "IMAGES_PATH          = \"/datastorage_fast/FIDS30_all\"\n",
    "IMAGES_LABELLED_PATH = \"/datastorage_fast/FIDS30\"\n",
    "\n",
    "store_dir            = \"/datastorage_fast/FIDS30_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:56:57.328996Z",
     "start_time": "2019-05-25T08:56:57.293803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/guava_32.jpg</td>\n",
       "      <td>guava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos\n",
       "3        /datastorage_fast/FIDS30_all/guava_32.jpg         guava\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "labels    = []\n",
    "\n",
    "for path, subdirs, files in os.walk(IMAGES_PATH):\n",
    "    for name in files:\n",
    "        if name.find(\".jpg\") != -1:\n",
    "            filenames.append(os.path.join(path, name))\n",
    "            labels.append(name.split(\"_\")[0])\n",
    "        \n",
    "metadata_images          = pd.DataFrame(filenames, columns=[\"Filename\"])\n",
    "metadata_images[\"label\"] = labels\n",
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:56:57.347579Z",
     "start_time": "2019-05-25T08:56:57.331495Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_image(img, height, width):\n",
    "    \n",
    "    is_color              = len(img.shape) == 3\n",
    "    src_height, src_width = img.shape[:2]\n",
    "    \n",
    "    # calc ratio\n",
    "    ratio = np.min([float(height) / src_height, float(width) / src_width])\n",
    "    \n",
    "    new_height = np.round(src_height * ratio).astype(int)\n",
    "    new_width  = np.round(src_width  * ratio).astype(int)\n",
    "    \n",
    "    img_reshaped = cv2.resize(img, (new_width,new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    if new_height < height:\n",
    "        \n",
    "        if is_color:\n",
    "            dims = (height - new_height, new_width, 3)\n",
    "        else:\n",
    "            dims = (height - new_height, new_width)\n",
    "        \n",
    "        padding      = np.ones(dims, dtype=np.uint8)\n",
    "        padding     *= 255\n",
    "        img_reshaped = np.concatenate([img_reshaped, padding], axis=0)\n",
    "    \n",
    "    elif new_width < width:\n",
    "        \n",
    "        if is_color:\n",
    "            dims = (new_height, width - new_width, 3)\n",
    "        else:\n",
    "            dims = (new_height, width - new_width)\n",
    "        \n",
    "        padding      = np.ones(dims, dtype=np.uint8)\n",
    "        padding     *= 255\n",
    "\n",
    "        img_reshaped = np.concatenate([img_reshaped, padding], axis=1)\n",
    "        \n",
    "    if not ((img_reshaped.shape[0] == height) & (img_reshaped.shape[1] == width)):\n",
    "        print(img_reshaped.shape)\n",
    "        raise Exception(\"resize error\")\n",
    "    \n",
    "    return img_reshaped, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:49.051185Z",
     "start_time": "2019-05-25T08:56:57.349968Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (971 of 971) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n"
     ]
    }
   ],
   "source": [
    "pbar = progressbar.ProgressBar(max_value=metadata_images.shape[0])\n",
    "\n",
    "document_images     = []\n",
    "image_metadata_idx  = []\n",
    "failed_idx          = []\n",
    "\n",
    "for i, f_name in pbar(enumerate(metadata_images.Filename.values)):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        img = cv2.imread(f_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img, _ = resize_image(img, height=128, width=128)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.        \n",
    "        \n",
    "        document_images.append(img)\n",
    "        image_metadata_idx.append(i)\n",
    "        \n",
    "    except:\n",
    "        failed_idx.append(i)\n",
    "\n",
    "document_images = np.array(document_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:49.068953Z",
     "start_time": "2019-05-25T08:57:49.055404Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_images.loc[image_metadata_idx, \"image_nr\"] = np.arange(len(image_metadata_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:49.079216Z",
     "start_time": "2019-05-25T08:57:49.073315Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_images = metadata_images[~metadata_images.image_nr.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:49.097855Z",
     "start_time": "2019-05-25T08:57:49.083023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "      <th>image_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/tomatoes_21.jpg</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label  image_nr\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons       0.0\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries       1.0\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos       2.0\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas       3.0\n",
       "5     /datastorage_fast/FIDS30_all/tomatoes_21.jpg      tomatoes       4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:50.611429Z",
     "start_time": "2019-05-25T08:57:49.100232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.constraints import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T10:48:29.875398Z",
     "start_time": "2019-05-25T10:48:28.755355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 12)      336       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 64, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64, 64, 12)        48        \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 24)        2616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 48)        10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 96)        41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 1,636,498\n",
      "Trainable params: 1,636,132\n",
      "Non-trainable params: 366\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "inputs = Input((128, 128, 3))\n",
    "\n",
    "# normalize inputs\n",
    "inp = BatchNormalization()(inputs)\n",
    "\n",
    "# === cnn ===\n",
    "\n",
    "activation = 'relu'\n",
    "filtnr     = 12\n",
    "\n",
    "cnn = Conv2D(filtnr, 3, activation = activation, padding = 'same')(inp)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn)\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*2, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn)\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*4, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn)\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "cnn = Conv2D(filtnr*8, 3, activation = activation, padding = 'same')(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2, 2), padding='same')(cnn)\n",
    "cnn = BatchNormalization()(cnn)\n",
    "#cnn = Dropout(0.2)(cnn)\n",
    "\n",
    "# === Bottleneck ===\n",
    "cnn = Flatten()(cnn)\n",
    "\n",
    "fc  = Dense(256, activation=\"relu\")(cnn)\n",
    "out = Dense(30,  activation=\"softmax\")(fc)\n",
    "\n",
    "\n",
    "model         = Model(input = inputs, output = out)\n",
    "\n",
    "model.compile(optimizer = Adam(lr=0.0002), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ground-truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:53.903498Z",
     "start_time": "2019-05-25T08:57:53.888138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>label</th>\n",
       "      <th>image_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/lemons_37.jpg</td>\n",
       "      <td>lemons</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/blackberries_7.jpg</td>\n",
       "      <td>blackberries</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/mangos_23.jpg</td>\n",
       "      <td>mangos</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/bananas_6.jpg</td>\n",
       "      <td>bananas</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/datastorage_fast/FIDS30_all/tomatoes_21.jpg</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename         label  image_nr\n",
       "0       /datastorage_fast/FIDS30_all/lemons_37.jpg        lemons       0.0\n",
       "1  /datastorage_fast/FIDS30_all/blackberries_7.jpg  blackberries       1.0\n",
       "2       /datastorage_fast/FIDS30_all/mangos_23.jpg        mangos       2.0\n",
       "4       /datastorage_fast/FIDS30_all/bananas_6.jpg       bananas       3.0\n",
       "5     /datastorage_fast/FIDS30_all/tomatoes_21.jpg      tomatoes       4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.404973Z",
     "start_time": "2019-05-25T08:57:53.905716Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerically encode string labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.413073Z",
     "start_time": "2019-05-25T08:57:54.407416Z"
    }
   },
   "outputs": [],
   "source": [
    "lencoder = LabelEncoder()\n",
    "lencoder.fit(metadata_images.label)\n",
    "\n",
    "labels_encoded = lencoder.transform(metadata_images.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encode labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.419767Z",
     "start_time": "2019-05-25T08:57:54.416053Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.434432Z",
     "start_time": "2019-05-25T08:57:54.422669Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(labels_encoded.reshape(-1, 1))\n",
    "\n",
    "labels_ohe = ohe.transform(labels_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.443187Z",
     "start_time": "2019-05-25T08:57:54.436964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.463780Z",
     "start_time": "2019-05-25T08:57:54.445520Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.469237Z",
     "start_time": "2019-05-25T08:57:54.465950Z"
    }
   },
   "outputs": [],
   "source": [
    "sss_tt = StratifiedShuffleSplit(n_splits=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.474721Z",
     "start_time": "2019-05-25T08:57:54.471388Z"
    }
   },
   "outputs": [],
   "source": [
    "tt_splits = sss_tt.split(document_images, labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.486984Z",
     "start_time": "2019-05-25T08:57:54.477142Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all_ids, test_ids = list(tt_splits)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.492323Z",
     "start_time": "2019-05-25T08:57:54.489072Z"
    }
   },
   "outputs": [],
   "source": [
    "sss_tv = StratifiedShuffleSplit(n_splits=1, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.640375Z",
     "start_time": "2019-05-25T08:57:54.497608Z"
    }
   },
   "outputs": [],
   "source": [
    "tv_splits = sss_tv.split(document_images[train_all_ids], labels_encoded[train_all_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.661344Z",
     "start_time": "2019-05-25T08:57:54.643184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids_rel, val_ids_rel = list(tv_splits)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.666612Z",
     "start_time": "2019-05-25T08:57:54.663360Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids = train_all_ids[train_ids_rel]\n",
    "val_ids   = train_all_ids[val_ids_rel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.673354Z",
     "start_time": "2019-05-25T08:57:54.669580Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:54.679142Z",
     "start_time": "2019-05-25T08:57:54.675899Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:57:55.325101Z",
     "start_time": "2019-05-25T08:57:54.681465Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nr += 1\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='/datastorage_fast/FIDS30_temp/%d' % model_nr, \n",
    "                                      histogram_freq=0, \n",
    "                                      batch_size=32, \n",
    "                                      write_graph=False, \n",
    "                                      write_grads=False, \n",
    "                                      write_images=False, \n",
    "                                      embeddings_freq=0, \n",
    "                                      embeddings_layer_names=None, \n",
    "                                      embeddings_metadata=None, \n",
    "                                      embeddings_data=None, \n",
    "                                      update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T08:58:18.973218Z",
     "start_time": "2019-05-25T08:57:55.327603Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schindler/anaconda/python2/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 822 samples, validate on 44 samples\n",
      "Epoch 1/50\n",
      "822/822 [==============================] - 4s 4ms/step - loss: 3.3920 - acc: 0.0523 - val_loss: 3.3366 - val_acc: 0.0455\n",
      "Epoch 2/50\n",
      "822/822 [==============================] - 0s 492us/step - loss: 3.3053 - acc: 0.0779 - val_loss: 3.2653 - val_acc: 0.0227\n",
      "Epoch 3/50\n",
      "822/822 [==============================] - 0s 434us/step - loss: 3.1983 - acc: 0.1071 - val_loss: 3.1470 - val_acc: 0.1136\n",
      "Epoch 4/50\n",
      "822/822 [==============================] - 0s 436us/step - loss: 3.0316 - acc: 0.1642 - val_loss: 2.9793 - val_acc: 0.1818\n",
      "Epoch 5/50\n",
      "822/822 [==============================] - 0s 436us/step - loss: 2.8303 - acc: 0.1764 - val_loss: 2.8495 - val_acc: 0.2045\n",
      "Epoch 6/50\n",
      "822/822 [==============================] - 0s 439us/step - loss: 2.6180 - acc: 0.2689 - val_loss: 2.7208 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "822/822 [==============================] - 0s 427us/step - loss: 2.4794 - acc: 0.2701 - val_loss: 2.5721 - val_acc: 0.2955\n",
      "Epoch 8/50\n",
      "822/822 [==============================] - 0s 444us/step - loss: 2.3060 - acc: 0.3260 - val_loss: 2.5069 - val_acc: 0.2727\n",
      "Epoch 9/50\n",
      "822/822 [==============================] - 0s 431us/step - loss: 2.2042 - acc: 0.3345 - val_loss: 2.5456 - val_acc: 0.2727\n",
      "Epoch 10/50\n",
      "822/822 [==============================] - 0s 451us/step - loss: 2.0509 - acc: 0.4100 - val_loss: 2.3928 - val_acc: 0.2273\n",
      "Epoch 11/50\n",
      "822/822 [==============================] - 0s 429us/step - loss: 1.8813 - acc: 0.4720 - val_loss: 2.2833 - val_acc: 0.2955\n",
      "Epoch 12/50\n",
      "822/822 [==============================] - 0s 442us/step - loss: 1.7726 - acc: 0.4903 - val_loss: 2.2933 - val_acc: 0.2500\n",
      "Epoch 13/50\n",
      "822/822 [==============================] - 0s 444us/step - loss: 1.7176 - acc: 0.4903 - val_loss: 2.2821 - val_acc: 0.2955\n",
      "Epoch 14/50\n",
      "822/822 [==============================] - 0s 437us/step - loss: 1.6134 - acc: 0.5000 - val_loss: 2.1569 - val_acc: 0.2727\n",
      "Epoch 15/50\n",
      "822/822 [==============================] - 0s 515us/step - loss: 1.5037 - acc: 0.5560 - val_loss: 2.1202 - val_acc: 0.2955\n",
      "Epoch 16/50\n",
      "822/822 [==============================] - 0s 452us/step - loss: 1.4390 - acc: 0.5864 - val_loss: 2.1484 - val_acc: 0.3409\n",
      "Epoch 17/50\n",
      "822/822 [==============================] - 0s 438us/step - loss: 1.3802 - acc: 0.5973 - val_loss: 2.0698 - val_acc: 0.3409\n",
      "Epoch 18/50\n",
      "822/822 [==============================] - 0s 430us/step - loss: 1.2857 - acc: 0.6302 - val_loss: 2.0409 - val_acc: 0.2955\n",
      "Epoch 19/50\n",
      "822/822 [==============================] - 0s 446us/step - loss: 1.2031 - acc: 0.6484 - val_loss: 2.0993 - val_acc: 0.3409\n",
      "Epoch 20/50\n",
      "822/822 [==============================] - 0s 438us/step - loss: 1.1874 - acc: 0.6496 - val_loss: 1.9782 - val_acc: 0.3182\n",
      "Epoch 21/50\n",
      "822/822 [==============================] - 0s 438us/step - loss: 1.0983 - acc: 0.7044 - val_loss: 2.0257 - val_acc: 0.3182\n",
      "Epoch 22/50\n",
      "822/822 [==============================] - 0s 482us/step - loss: 1.0630 - acc: 0.6849 - val_loss: 2.1441 - val_acc: 0.3409\n",
      "Epoch 23/50\n",
      "822/822 [==============================] - 0s 507us/step - loss: 1.0165 - acc: 0.7129 - val_loss: 1.9396 - val_acc: 0.3409\n",
      "Epoch 24/50\n",
      "822/822 [==============================] - 0s 478us/step - loss: 0.9178 - acc: 0.7555 - val_loss: 1.9965 - val_acc: 0.3864\n",
      "Epoch 25/50\n",
      "822/822 [==============================] - 0s 439us/step - loss: 0.8904 - acc: 0.7506 - val_loss: 1.9518 - val_acc: 0.4318\n",
      "Epoch 26/50\n",
      "822/822 [==============================] - 0s 435us/step - loss: 0.8602 - acc: 0.7555 - val_loss: 1.9920 - val_acc: 0.3864\n",
      "Epoch 27/50\n",
      "822/822 [==============================] - 0s 429us/step - loss: 0.7755 - acc: 0.8102 - val_loss: 1.9983 - val_acc: 0.3182\n",
      "Epoch 28/50\n",
      "822/822 [==============================] - 0s 430us/step - loss: 0.7469 - acc: 0.7725 - val_loss: 2.0597 - val_acc: 0.4318\n",
      "Epoch 29/50\n",
      "822/822 [==============================] - 0s 433us/step - loss: 0.7100 - acc: 0.8102 - val_loss: 1.9123 - val_acc: 0.4773\n",
      "Epoch 30/50\n",
      "822/822 [==============================] - 0s 444us/step - loss: 0.6394 - acc: 0.8309 - val_loss: 2.0320 - val_acc: 0.3864\n",
      "Epoch 31/50\n",
      "822/822 [==============================] - 0s 435us/step - loss: 0.6381 - acc: 0.8260 - val_loss: 2.0071 - val_acc: 0.4318\n",
      "Epoch 32/50\n",
      "822/822 [==============================] - 0s 425us/step - loss: 0.5985 - acc: 0.8479 - val_loss: 2.0346 - val_acc: 0.4091\n",
      "Epoch 33/50\n",
      "822/822 [==============================] - 0s 427us/step - loss: 0.6040 - acc: 0.8394 - val_loss: 2.1160 - val_acc: 0.4091\n",
      "Epoch 34/50\n",
      "822/822 [==============================] - 0s 441us/step - loss: 0.4933 - acc: 0.8771 - val_loss: 2.0562 - val_acc: 0.3864\n",
      "Epoch 35/50\n",
      "822/822 [==============================] - 0s 445us/step - loss: 0.4511 - acc: 0.8917 - val_loss: 2.1932 - val_acc: 0.3409\n",
      "Epoch 36/50\n",
      "822/822 [==============================] - 0s 488us/step - loss: 0.4822 - acc: 0.8759 - val_loss: 2.2250 - val_acc: 0.3636\n",
      "Epoch 37/50\n",
      "822/822 [==============================] - 0s 534us/step - loss: 0.4044 - acc: 0.9063 - val_loss: 2.2308 - val_acc: 0.3636\n",
      "Epoch 38/50\n",
      "822/822 [==============================] - 0s 467us/step - loss: 0.4377 - acc: 0.8881 - val_loss: 2.0460 - val_acc: 0.4091\n",
      "Epoch 39/50\n",
      "822/822 [==============================] - 0s 452us/step - loss: 0.3811 - acc: 0.9100 - val_loss: 2.2219 - val_acc: 0.4091\n",
      "Epoch 40/50\n",
      "822/822 [==============================] - 0s 444us/step - loss: 0.3903 - acc: 0.8905 - val_loss: 2.0467 - val_acc: 0.4091\n",
      "Epoch 41/50\n",
      "822/822 [==============================] - 0s 498us/step - loss: 0.3179 - acc: 0.9367 - val_loss: 2.2017 - val_acc: 0.4091\n",
      "Epoch 42/50\n",
      "822/822 [==============================] - 0s 475us/step - loss: 0.3074 - acc: 0.9282 - val_loss: 2.2037 - val_acc: 0.4091\n",
      "Epoch 43/50\n",
      "822/822 [==============================] - 0s 459us/step - loss: 0.2972 - acc: 0.9343 - val_loss: 2.2866 - val_acc: 0.4091\n",
      "Epoch 44/50\n",
      "822/822 [==============================] - 0s 494us/step - loss: 0.3515 - acc: 0.9124 - val_loss: 2.3045 - val_acc: 0.3864\n",
      "Epoch 45/50\n",
      "822/822 [==============================] - 0s 540us/step - loss: 0.2610 - acc: 0.9538 - val_loss: 2.2144 - val_acc: 0.3864\n",
      "Epoch 46/50\n",
      "822/822 [==============================] - 0s 444us/step - loss: 0.2183 - acc: 0.9684 - val_loss: 2.3645 - val_acc: 0.4545\n",
      "Epoch 47/50\n",
      "822/822 [==============================] - 0s 462us/step - loss: 0.2398 - acc: 0.9513 - val_loss: 2.2832 - val_acc: 0.4318\n",
      "Epoch 48/50\n",
      "822/822 [==============================] - 0s 467us/step - loss: 0.2408 - acc: 0.9416 - val_loss: 2.3085 - val_acc: 0.4091\n",
      "Epoch 49/50\n",
      "822/822 [==============================] - 0s 525us/step - loss: 0.2034 - acc: 0.9720 - val_loss: 2.4007 - val_acc: 0.3636\n",
      "Epoch 50/50\n",
      "822/822 [==============================] - 0s 455us/step - loss: 0.1733 - acc: 0.9720 - val_loss: 2.4365 - val_acc: 0.4318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48706a6438>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(document_images[train_ids], \n",
    "          labels_ohe[train_ids], \n",
    "          batch_size = 64,\n",
    "          epochs     = 50,\n",
    "          validation_data = (document_images[val_ids], labels_ohe[val_ids]),\n",
    "          callbacks=[tb_callback],\n",
    "          verbose    = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:43.462643Z",
     "start_time": "2019-05-25T09:02:43.457730Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:43.711368Z",
     "start_time": "2019-05-25T09:02:43.701090Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(featurewise_center=False, \n",
    "                                   samplewise_center=False, \n",
    "                                   featurewise_std_normalization=False, \n",
    "                                   samplewise_std_normalization=False, \n",
    "                                   zca_whitening=False, \n",
    "                                   zca_epsilon=1e-06, \n",
    "                                   rotation_range=90, \n",
    "                                   width_shift_range=10.0, \n",
    "                                   height_shift_range=10.0, \n",
    "                                   brightness_range=None, \n",
    "                                   shear_range=0.0, \n",
    "                                   zoom_range=10.0, \n",
    "                                   channel_shift_range=0.0, \n",
    "                                   fill_mode='constant', \n",
    "                                   cval=1.0, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True, \n",
    "                                   rescale=None, \n",
    "                                   preprocessing_function=None, \n",
    "                                   data_format=None, \n",
    "                                   validation_split=0.0, \n",
    "                                   dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:44.287007Z",
     "start_time": "2019-05-25T09:02:43.918101Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen_train.fit(document_images[train_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:44.298241Z",
     "start_time": "2019-05-25T09:02:44.290427Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen_val = ImageDataGenerator(featurewise_center=False, \n",
    "                                 samplewise_center=False, \n",
    "                                 featurewise_std_normalization=False, \n",
    "                                 samplewise_std_normalization=False, \n",
    "                                 zca_whitening=False, \n",
    "                                 zca_epsilon=1e-06, \n",
    "                                 rotation_range=0, \n",
    "                                 width_shift_range=0.0, \n",
    "                                 height_shift_range=0.0, \n",
    "                                 brightness_range=None, \n",
    "                                 shear_range=0.0, \n",
    "                                 zoom_range=0.0, \n",
    "                                 channel_shift_range=0.0, \n",
    "                                 fill_mode='constant', \n",
    "                                 cval=1.0, \n",
    "                                 horizontal_flip=False, \n",
    "                                 vertical_flip=False, \n",
    "                                 rescale=None, \n",
    "                                 preprocessing_function=None, \n",
    "                                 data_format=None, \n",
    "                                 validation_split=0.0, \n",
    "                                 dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:44.424997Z",
     "start_time": "2019-05-25T09:02:44.409112Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen_val.fit(document_images[val_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:02:44.765444Z",
     "start_time": "2019-05-25T09:02:44.761298Z"
    }
   },
   "outputs": [],
   "source": [
    "model_aug_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T10:48:38.822600Z",
     "start_time": "2019-05-25T10:48:38.815256Z"
    }
   },
   "outputs": [],
   "source": [
    "model_aug_nr += 1\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='/datastorage_fast/FIDS30_temp/aug_%d' % model_aug_nr, \n",
    "                                      histogram_freq=0, \n",
    "                                      batch_size=32, \n",
    "                                      write_graph=False, \n",
    "                                      write_grads=False, \n",
    "                                      write_images=False, \n",
    "                                      embeddings_freq=0, \n",
    "                                      embeddings_layer_names=None, \n",
    "                                      embeddings_metadata=None, \n",
    "                                      embeddings_data=None, \n",
    "                                      update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T10:50:55.604524Z",
     "start_time": "2019-05-25T10:48:39.385755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/12 [==============================] - 3s 240ms/step - loss: 3.8012 - acc: 0.0427 - val_loss: 5.1851 - val_acc: 0.0227\n",
      "Epoch 2/50\n",
      "13/12 [==============================] - 3s 192ms/step - loss: 3.5465 - acc: 0.0572 - val_loss: 4.8760 - val_acc: 0.0455\n",
      "Epoch 3/50\n",
      "13/12 [==============================] - 3s 210ms/step - loss: 3.4089 - acc: 0.0764 - val_loss: 4.8148 - val_acc: 0.0682\n",
      "Epoch 4/50\n",
      "13/12 [==============================] - 3s 211ms/step - loss: 3.2777 - acc: 0.0949 - val_loss: 4.5537 - val_acc: 0.1364\n",
      "Epoch 5/50\n",
      "13/12 [==============================] - 3s 211ms/step - loss: 3.2275 - acc: 0.0898 - val_loss: 4.4340 - val_acc: 0.0909\n",
      "Epoch 6/50\n",
      "13/12 [==============================] - 3s 211ms/step - loss: 3.0658 - acc: 0.1344 - val_loss: 4.3396 - val_acc: 0.0909\n",
      "Epoch 7/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 3.0602 - acc: 0.1269 - val_loss: 3.7855 - val_acc: 0.1818\n",
      "Epoch 8/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 2.9411 - acc: 0.1516 - val_loss: 3.7029 - val_acc: 0.2045\n",
      "Epoch 9/50\n",
      "13/12 [==============================] - 3s 211ms/step - loss: 2.8829 - acc: 0.1472 - val_loss: 3.5608 - val_acc: 0.2045\n",
      "Epoch 10/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.7646 - acc: 0.1689 - val_loss: 3.7122 - val_acc: 0.1818\n",
      "Epoch 11/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.7638 - acc: 0.1647 - val_loss: 3.6083 - val_acc: 0.1591\n",
      "Epoch 12/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.6768 - acc: 0.1909 - val_loss: 3.6073 - val_acc: 0.1818\n",
      "Epoch 13/50\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 2.6522 - acc: 0.2110 - val_loss: 3.5361 - val_acc: 0.1818\n",
      "Epoch 14/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.6232 - acc: 0.1938 - val_loss: 3.3967 - val_acc: 0.1818\n",
      "Epoch 15/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.5559 - acc: 0.1935 - val_loss: 3.0500 - val_acc: 0.2500\n",
      "Epoch 16/50\n",
      "13/12 [==============================] - 3s 211ms/step - loss: 2.5345 - acc: 0.2032 - val_loss: 2.9655 - val_acc: 0.2727\n",
      "Epoch 17/50\n",
      "13/12 [==============================] - 3s 207ms/step - loss: 2.5420 - acc: 0.2278 - val_loss: 3.1314 - val_acc: 0.2500\n",
      "Epoch 18/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 2.4813 - acc: 0.2461 - val_loss: 2.8385 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 2.3863 - acc: 0.2521 - val_loss: 2.9777 - val_acc: 0.2273\n",
      "Epoch 20/50\n",
      "13/12 [==============================] - 3s 209ms/step - loss: 2.3909 - acc: 0.2417 - val_loss: 2.9978 - val_acc: 0.2045\n",
      "Epoch 21/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.4051 - acc: 0.2421 - val_loss: 3.0571 - val_acc: 0.2045\n",
      "Epoch 22/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.3795 - acc: 0.2543 - val_loss: 3.0339 - val_acc: 0.1591\n",
      "Epoch 23/50\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 2.2882 - acc: 0.2864 - val_loss: 2.6779 - val_acc: 0.2727\n",
      "Epoch 24/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.3177 - acc: 0.2854 - val_loss: 2.6462 - val_acc: 0.2955\n",
      "Epoch 25/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 2.2654 - acc: 0.2742 - val_loss: 2.5651 - val_acc: 0.2955\n",
      "Epoch 26/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 2.3207 - acc: 0.2533 - val_loss: 2.9098 - val_acc: 0.2727\n",
      "Epoch 27/50\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 2.2892 - acc: 0.2738 - val_loss: 2.9716 - val_acc: 0.3182\n",
      "Epoch 28/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.2679 - acc: 0.2581 - val_loss: 3.0134 - val_acc: 0.2273\n",
      "Epoch 29/50\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 2.2322 - acc: 0.2868 - val_loss: 2.7348 - val_acc: 0.3409\n",
      "Epoch 30/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 2.2486 - acc: 0.2752 - val_loss: 2.3493 - val_acc: 0.3636\n",
      "Epoch 31/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 2.2153 - acc: 0.2687 - val_loss: 2.6073 - val_acc: 0.2955\n",
      "Epoch 32/50\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 2.2520 - acc: 0.2874 - val_loss: 3.0142 - val_acc: 0.2500\n",
      "Epoch 33/50\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 2.1529 - acc: 0.3059 - val_loss: 2.7983 - val_acc: 0.2727\n",
      "Epoch 34/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.1430 - acc: 0.2989 - val_loss: 2.6827 - val_acc: 0.2955\n",
      "Epoch 35/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 2.1843 - acc: 0.3141 - val_loss: 2.4970 - val_acc: 0.2727\n",
      "Epoch 36/50\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 2.1356 - acc: 0.2924 - val_loss: 2.4276 - val_acc: 0.3636\n",
      "Epoch 37/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 2.1770 - acc: 0.3014 - val_loss: 2.4420 - val_acc: 0.2273\n",
      "Epoch 38/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.0834 - acc: 0.3305 - val_loss: 2.4460 - val_acc: 0.2955\n",
      "Epoch 39/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.0398 - acc: 0.3309 - val_loss: 2.4907 - val_acc: 0.2500\n",
      "Epoch 40/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 2.0456 - acc: 0.3311 - val_loss: 2.6292 - val_acc: 0.2273\n",
      "Epoch 41/50\n",
      "13/12 [==============================] - 3s 206ms/step - loss: 2.0842 - acc: 0.3323 - val_loss: 2.6868 - val_acc: 0.3182\n",
      "Epoch 42/50\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 2.0559 - acc: 0.3139 - val_loss: 2.4639 - val_acc: 0.2500\n",
      "Epoch 43/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 2.0697 - acc: 0.3207 - val_loss: 2.4077 - val_acc: 0.2273\n",
      "Epoch 44/50\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 2.0337 - acc: 0.3259 - val_loss: 2.5396 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 2.0000 - acc: 0.3398 - val_loss: 2.6514 - val_acc: 0.3182\n",
      "Epoch 46/50\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 1.9912 - acc: 0.3470 - val_loss: 2.7323 - val_acc: 0.2955\n",
      "Epoch 47/50\n",
      "13/12 [==============================] - 3s 210ms/step - loss: 1.9491 - acc: 0.3596 - val_loss: 2.2286 - val_acc: 0.2727\n",
      "Epoch 48/50\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 2.0511 - acc: 0.3422 - val_loss: 2.4603 - val_acc: 0.1818\n",
      "Epoch 49/50\n",
      "13/12 [==============================] - 3s 212ms/step - loss: 1.9906 - acc: 0.3295 - val_loss: 2.5583 - val_acc: 0.3182\n",
      "Epoch 50/50\n",
      "13/12 [==============================] - 3s 203ms/step - loss: 1.9284 - acc: 0.3682 - val_loss: 2.3937 - val_acc: 0.2045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44f92681d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen_train.flow(document_images[train_ids], labels_ohe[train_ids], batch_size=64),\n",
    "                    validation_data = datagen_val.flow(document_images[val_ids], labels_ohe[val_ids], batch_size=12),\n",
    "                    steps_per_epoch = train_ids.shape[0] / 64, \n",
    "                    validation_steps= val_ids.shape[0] / 12,\n",
    "                    callbacks=[tb_callback],\n",
    "                    verbose=1,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T09:04:59.827489Z",
     "start_time": "2019-05-25T09:04:59.754002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 485us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.507881219239579, 0.2268041237113402]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(document_images[test_ids], labels_ohe[test_ids])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
